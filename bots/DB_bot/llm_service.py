"""
LLM service for generating intelligent responses using OpenRouter.
"""
import openai
import structlog
from typing import Dict, List, Optional, Any
from datetime import datetime
from config import config
from db_api import TrainDeparture
import json

logger = structlog.get_logger()

class LLMService:
    """Service for generating natural language responses about train information."""
    
    def __init__(self):
        if config.OPENROUTER_API_KEY:
            self.client = openai.OpenAI(
                api_key=config.OPENROUTER_API_KEY,
                base_url=config.OPENROUTER_BASE_URL
            )
        else:
            self.client = None
            logger.warning("OpenRouter API key not configured - using fallback responses")
    
    async def generate_connection_summary(self, connection_data: Dict[str, Any]) -> str:
        """Generate a natural language summary of train connection status."""
        if not self.client:
            return self._generate_fallback_summary(connection_data)
        
        try:
            # Prepare the data for the LLM
            trains_info = []
            for train in connection_data.get("trains", []):
                train_info = {
                    "train_number": train.train_number,
                    "destination": train.destination,
                    "scheduled_time": train.scheduled_time.strftime("%H:%M"),
                    "delay_minutes": train.delay_minutes,
                    "platform": train.platform,
                    "is_cancelled": train.is_cancelled,
                    "messages": train.messages
                }
                trains_info.append(train_info)
            
            summary = connection_data.get("summary", {})
            
            prompt = f"""
Erstelle eine freundliche und informative Zusammenfassung der aktuellen Zugverbindung von {connection_data['from_station']} nach {connection_data['to_station']}.

Aktuelle Zugdaten:
{json.dumps(trains_info, indent=2, ensure_ascii=False)}

Zusammenfassung:
- Durchschnittliche VerspÃ¤tung: {summary.get('average_delay', 0):.1f} Minuten
- Maximale VerspÃ¤tung: {summary.get('max_delay', 0)} Minuten
- PÃ¼nktlichkeitsrate: {summary.get('on_time_ratio', 0)*100:.0f}%
- AusfÃ¤lle: {summary.get('cancelled_trains', 0)}

Anforderungen:
- Verwende freundlichen, hilfreichen Ton
- Fasse die wichtigsten Informationen zusammen
- ErwÃ¤hne auffÃ¤llige VerspÃ¤tungen oder AusfÃ¤lle
- Gib praktische Empfehlungen wenn nÃ¶tig
- Antwort auf Deutsch
- Maximal 3 SÃ¤tze
- Verwende Emojis fÃ¼r bessere Lesbarkeit
"""

            response = self.client.chat.completions.create(
                model=config.DEFAULT_LLM_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "Du bist ein hilfreicher Assistent fÃ¼r Deutsche Bahn Verbindungen. Antworte knapp und freundlich."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error("Failed to generate LLM response", error=str(e))
            return self._generate_fallback_summary(connection_data)
    
    def _generate_fallback_summary(self, connection_data: Dict[str, Any]) -> str:
        """Generate a simple fallback summary when LLM is not available."""
        from_station = connection_data.get("from_station", "")
        to_station = connection_data.get("to_station", "")
        summary = connection_data.get("summary", {})
        trains = connection_data.get("trains", [])
        
        avg_delay = summary.get("average_delay", 0)
        cancelled = summary.get("cancelled_trains", 0)
        
        # Build a simple summary
        if not trains:
            return f"ğŸš« Keine aktuellen Zugdaten fÃ¼r {from_station} â†’ {to_station} verfÃ¼gbar."
        
        status_emoji = "ğŸŸ¢" if avg_delay <= 2 else "ğŸŸ¡" if avg_delay <= 10 else "ğŸ”´"
        
        result = f"{status_emoji} **{from_station} â†’ {to_station}**\n"
        
        if cancelled > 0:
            result += f"âš ï¸ {cancelled} Zug(zÃ¼ge) ausgefallen! "
        
        if avg_delay <= 2:
            result += "ZÃ¼ge fahren weitgehend pÃ¼nktlich âœ…"
        elif avg_delay <= 5:
            result += f"Leichte VerspÃ¤tungen (~{avg_delay:.0f} Min) ğŸ•"
        elif avg_delay <= 15:
            result += f"Mittlere VerspÃ¤tungen (~{avg_delay:.0f} Min) â°"
        else:
            result += f"Erhebliche VerspÃ¤tungen (~{avg_delay:.0f} Min) ğŸš¨"
        
        # Add next train info
        if trains:
            next_train = trains[0]
            delay_text = f"+{next_train.delay_minutes}'" if next_train.delay_minutes > 0 else "pÃ¼nktlich"
            result += f"\nğŸš† NÃ¤chster Zug: {next_train.train_number} um {next_train.scheduled_time.strftime('%H:%M')} ({delay_text})"
        
        return result
    
    async def generate_help_message(self) -> str:
        """Generate a help message for bot commands."""
        if not self.client:
            return self._get_fallback_help()
        
        try:
            prompt = """
Erstelle eine kurze, freundliche Hilfe-Nachricht fÃ¼r einen Deutsche Bahn Discord Bot.

Der Bot hat folgende Befehle:
- /db-status - Zeigt alle gespeicherten Verbindungen an
- /db-setup [von] [nach] - Speichert eine neue Verbindung (max. 3)
- /db-check [von] [nach] - PrÃ¼ft eine spezifische Verbindung
- /db-help - Zeigt diese Hilfe an

Anforderungen:
- Freundlicher, hilfsbereiter Ton
- Kurze ErklÃ¤rung was der Bot kann
- Beispiel fÃ¼r einen Befehl
- Auf Deutsch
- Mit passenden Emojis
- Maximal 5 Zeilen
"""

            response = self.client.chat.completions.create(
                model=config.DEFAULT_LLM_MODEL,
                messages=[
                    {
                        "role": "system",
                        "content": "Du bist ein hilfreicher Discord Bot Assistent. Erstelle knapp und klar."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=250,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error("Failed to generate help message", error=str(e))
            return self._get_fallback_help()
    
    def _get_fallback_help(self) -> str:
        """Fallback help message when LLM is not available."""
        return """ğŸš† **Deutsche Bahn Bot Hilfe**

ğŸ” `/db-status` - Zeige deine gespeicherten Verbindungen
ğŸ’¾ `/db-setup MÃ¼nchen Hamburg` - Speichere eine neue Verbindung
ğŸ“Š `/db-check Berlin Frankfurt` - PrÃ¼fe eine spezifische Verbindung  
â“ `/db-help` - Zeige diese Hilfe

Du kannst bis zu 3 Verbindungen speichern fÃ¼r schnellen Zugriff! ğŸ¯"""
    
    async def generate_error_message(self, error_type: str, context: str = "") -> str:
        """Generate a user-friendly error message."""
        error_messages = {
            "station_not_found": f"ğŸš« Station '{context}' wurde nicht gefunden. Bitte prÃ¼fe die Schreibweise.",
            "max_connections": f"âš ï¸ Du hast bereits {config.MAX_CONNECTIONS_PER_USER} Verbindungen gespeichert. Entferne zuerst eine alte Verbindung.",
            "connection_exists": f"ğŸ“ Die Verbindung '{context}' ist bereits gespeichert.",
            "no_connections": "ğŸ“‹ Du hast noch keine Verbindungen gespeichert. Nutze `/db-setup [von] [nach]` um eine zu erstellen.",
            "api_error": "ğŸ”§ Entschuldigung, es gab ein Problem beim Abrufen der Zugdaten. Versuche es bitte spÃ¤ter nochmal.",
            "general": "âŒ Es ist ein Fehler aufgetreten. Bitte versuche es erneut."
        }
        
        return error_messages.get(error_type, error_messages["general"])

# Create a global LLM service instance
llm_service = LLMService() 